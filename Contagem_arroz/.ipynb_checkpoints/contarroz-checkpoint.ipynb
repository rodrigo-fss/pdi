{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eduardo Darrazão\n",
    "#Rodrigo Faria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.setrecursionlimit(2000)\n",
    "\n",
    "global kernel\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "global kernel2\n",
    "kernel2 = np.ones((2,2),np.uint8)\n",
    "\n",
    "global ALTURA_MIN\n",
    "global LARGURA_MIN\n",
    "global N_PIXELS_MIN\n",
    "global SOMA\n",
    "\n",
    "ALTURA_MIN = 5\n",
    "LARGURA_MIN = 5\n",
    "N_PIXELS_MIN = 20\n",
    "SOMA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Component:\n",
    "    def __init__(self, label, n_pixels):\n",
    "        self.label = label\n",
    "        self.n_pixels = n_pixels\n",
    "\n",
    "def rotula (entrada, componentes, largura_min, altura_min, n_pixels_min):\n",
    "    label = 0.1\n",
    "    #Inicia Lista de componentes\n",
    "    componentes = []\n",
    "    \n",
    "    for altura in range(entrada.shape[0]):\n",
    "        for largura in range(entrada.shape[1]):\n",
    "            #Se o pixel for branco\n",
    "            if entrada[altura][largura] == 255:\n",
    "                #Comece a inundação\n",
    "                componente = inunda(label, entrada, altura, largura, 1)                \n",
    "                #Se o objeto inundado tiver mais pixels do que o numero minimo definido\n",
    "                if componente != 0:\n",
    "                    #Adicione ao lista de componentes e incremente a label\n",
    "                    componentes.append(componente)\n",
    "                    label = label+0.1\n",
    "    #printando todos os componentes encontrados\n",
    "    print 'Numero de Componentes: ' + str(len(componentes))\n",
    "    return SOMA/len(componentes)\n",
    "\n",
    "\n",
    "def inunda(label, entrada, x, y, ind):\n",
    "    n_pixels_cont = 1\n",
    "    entrada[x][y] = label\n",
    "    \n",
    "    if (x+1)<entrada.shape[0] or (y+1)<entrada.shape[1]:\n",
    "        #Visite seu quatro vizinhos e verifique se fazem parte do objeto\n",
    "        if entrada[x-1][y] == 255:\n",
    "            #Se fizerem, prossiga com a inundação recursiva nessa direção\n",
    "            n_pixels_cont = inunda(label, entrada, x-1, y, 0) + 1\n",
    "        if entrada[x][y-1] == 255:\n",
    "            n_pixels_cont  = inunda(label, entrada, x, y-1, 0) + 1\n",
    "        if entrada[x+1][y] == 255:\n",
    "            n_pixels_cont = inunda(label, entrada, x+1, y, 0) + 1\n",
    "        if entrada[x][y+1] == 255:\n",
    "            n_pixels_cont  = inunda(label, entrada, x, y+1, 0) + 1\n",
    "    \n",
    "    #A variavel ind verifica se estamos na primeira chamada do objeto, assim, se a inundação foi finalizada\n",
    "    if ind == 1:\n",
    "        #Se for, verifique se o numero de pixels do objeto é maior que o minimo definido\n",
    "        if n_pixels_cont >= N_PIXELS_MIN:\n",
    "            SOMA = SOMA + n_pixels_cont\n",
    "            #Se for, crie um componente e retorne\n",
    "            componente = Component(label, n_pixels_cont)\n",
    "            return componente\n",
    "        else:\n",
    "            return 0\n",
    "    #Se não for a primeira chamada, retorne a contagem de pixels do objeto para ser incrementada com as outras chamadas\n",
    "    else:\n",
    "        return n_pixels_cont\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trataImagem2(img):\n",
    "    #THRESHOLD ADAPTATIVO\n",
    "    imgthresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 101, -30)\n",
    "    \n",
    "    for img in range(1):\n",
    "        #OPENING\n",
    "        imgthresh = cv2.morphologyEx(imgthresh, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    #ERODE   \n",
    "    imgthresh = cv2.erode(imgthresh,kernel2,iterations = 1)\n",
    "    \n",
    "    #LAPLACIANO\n",
    "    laplacian = cv2.Laplacian(imgthresh, cv2.CV_64F)\n",
    "    laplacian = cv2.dilate(laplacian,kernel2,iterations = 2)\n",
    "    imgthresh = imgthresh - laplacian\n",
    "    \n",
    "    #ERODE   \n",
    "    imgthresh = cv2.erode(imgthresh,kernel2,iterations = 1)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    imgthresh = imgthresh.astype(np.uint8)\n",
    "    dist_transform = cv2.distanceTransform(imgthresh,cv2.cv.CV_DIST_L2,3) \n",
    "    cv2.imshow('dissst', dist_transform)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    n_componentes = rotula(imgthresh.copy(), 0, ALTURA_MIN, LARGURA_MIN, N_PIXELS_MIN)\n",
    "    \n",
    "    return imgthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trataImagem3(img):\n",
    "    #Load image in grayscale\n",
    "    #img = cv2.imread('Results\\Feb_16-0.jpg',0)\n",
    "\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    blur = cv2.GaussianBlur(opening,(1,1),0)\n",
    "    ret3,th4 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=1)\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.cv.DIST_L2,3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers+1\n",
    "    markers[unknown==255] = 0\n",
    "    markers = markers.astype('int32')\n",
    "\n",
    "    #now load same image as color image\n",
    "    img = cv2.imread('\"60.bmp',1)\n",
    "\n",
    "    markers = cv2.watershed(img,markers)\n",
    "    img[markers == -1] = [255,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trataImagem(img):\n",
    "    \n",
    "    #THRESHOLD ADAPTATIVO\n",
    "    imgthresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 101, -30)        \n",
    "    \n",
    "    for img in range(1):\n",
    "        #OPENING\n",
    "        imgthresh = cv2.morphologyEx(imgthresh, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    #ERODE   \n",
    "    imgthresh = cv2.erode(imgthresh,kernel2,iterations = 4)\n",
    "    n_componentes = rotula(imgthresh.copy(), 0, ALTURA_MIN, LARGURA_MIN, N_PIXELS_MIN)\n",
    "    \n",
    "    return imgthresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'SOMA' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2024fb1b3424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"205.bmp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg1thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrataImagem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mSOMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimg2thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrataImagem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5b92f0671f55>\u001b[0m in \u001b[0;36mtrataImagem\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#ERODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimgthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgthresh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mn_componentes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgthresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALTURA_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLARGURA_MIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_PIXELS_MIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimgthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-c68f4ddb32af>\u001b[0m in \u001b[0;36mrotula\u001b[0;34m(entrada, componentes, largura_min, altura_min, n_pixels_min)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentrada\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maltura\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlargura\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m#Comece a inundação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mcomponente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minunda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltura\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargura\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;31m#Se o objeto inundado tiver mais pixels do que o numero minimo definido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcomponente\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-c68f4ddb32af>\u001b[0m in \u001b[0;36minunda\u001b[0;34m(label, entrada, x, y, ind)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#Se for, verifique se o numero de pixels do objeto é maior que o minimo definido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_pixels_cont\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN_PIXELS_MIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mSOMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSOMA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_pixels_cont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;31m#Se for, crie um componente e retorne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mcomponente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComponent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pixels_cont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'SOMA' referenced before assignment"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread(\"60.bmp\", cv2.IMREAD_GRAYSCALE )\n",
    "img2 = cv2.imread(\"82.bmp\", cv2.IMREAD_GRAYSCALE )\n",
    "img3 = cv2.imread(\"114.bmp\", cv2.IMREAD_GRAYSCALE )\n",
    "img4 = cv2.imread(\"150.bmp\", cv2.IMREAD_GRAYSCALE )\n",
    "img5 = cv2.imread(\"205.bmp\", cv2.IMREAD_GRAYSCALE )\n",
    "\n",
    "img1thresh = trataImagem(img1)\n",
    "SOMA = 0\n",
    "img2thresh = trataImagem(img2)\n",
    "SOMA = 0\n",
    "img3thresh = trataImagem(img3)\n",
    "SOMA = 0\n",
    "img4thresh = trataImagem(img4)\n",
    "SOMA = 0\n",
    "img5thresh = trataImagem(img5)\n",
    "SOMA = 0\n",
    "    \n",
    "cv2.imwrite('im1.bmp', img1thresh)\n",
    "cv2.imwrite('im2.bmp', img2thresh)\n",
    "cv2.imwrite('im3.bmp', img3thresh)\n",
    "cv2.imwrite('im4.bmp', img4thresh)\n",
    "cv2.imwrite('im5.bmp', img5thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
